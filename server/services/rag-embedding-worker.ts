import { getAzureDatabricksService } from "./azure-databricks.js";
import { getAzureSearchService } from "./azure-search.js";
import { ragEmbeddingManager } from "./rag-embedding-manager.js";
import { ragService } from "./rag.js";
import type { RagEmbeddingSchema, RagEmbeddingJob } from "@shared/schema";

/**
 * RAG Embedding Worker
 * 
 * Databricks ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•˜ê³  AI Searchì— ì—…ë¡œë“œí•˜ëŠ” ì›Œì»¤
 */

export interface EmbeddingWorkerOptions {
  batchSize?: number;
  onProgress?: (progress: {
    processed: number;
    total: number;
    percentage: number;
  }) => void;
}

export class RAGEmbeddingWorker {
  /**
   * ì„ë² ë”© ì‘ì—… ì‹¤í–‰
   */
  async executeJob(
    job: RagEmbeddingJob,
    schema: RagEmbeddingSchema,
    options?: EmbeddingWorkerOptions
  ): Promise<void> {
    const batchSize = options?.batchSize || job.batchSize || 1000;
    
    try {
      // ì‘ì—… ìƒíƒœë¥¼ RUNNINGìœ¼ë¡œ ì—…ë°ì´íŠ¸
      await ragEmbeddingManager.updateJobStatus(job.id, "RUNNING", {
        startTime: new Date(),
      });

      // Databricksì—ì„œ ë°ì´í„° ì¡°íšŒ
      const databricksService = getAzureDatabricksService();
      await databricksService.initialize();

      // ì¿¼ë¦¬ êµ¬ì„±
      const query = this.buildQuery(schema, job);
      
      console.log(`ğŸ”„ [Job ${job.id}] Databricks ì¿¼ë¦¬ ì‹¤í–‰: ${query.substring(0, 100)}...`);
      
      // ì „ì²´ ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ
      const countQuery = this.buildCountQuery(schema, job);
      const countResult = await databricksService.executeQuery(countQuery);
      const totalRecords = countResult.rowCount || 0;

      console.log(`ğŸ“Š [Job ${job.id}] ì „ì²´ ë ˆì½”ë“œ ìˆ˜: ${totalRecords}`);

      // ì‘ì—… ì—…ë°ì´íŠ¸
      await ragEmbeddingManager.updateJobStatus(job.id, "RUNNING", {
        totalRecords,
      });

      // ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
      let processedRecords = 0;
      let failedRecords = 0;
      let offset = 0;

      while (offset < totalRecords) {
        // ì·¨ì†Œ í™•ì¸
        const currentJob = await ragEmbeddingManager.getJob(job.id);
        if (currentJob?.jobStatus === "CANCELLED") {
          console.log(`âš ï¸ [Job ${job.id}] ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤`);
          return;
        }

        // ë°°ì¹˜ ë°ì´í„° ì¡°íšŒ
        const batchQuery = this.buildQuery(schema, job, offset, batchSize);
        const batchResult = await databricksService.executeQuery(batchQuery);
        const batchData = batchResult.data || [];

        if (batchData.length === 0) {
          break;
        }

        console.log(`ğŸ“¦ [Job ${job.id}] ë°°ì¹˜ ì²˜ë¦¬: ${offset + 1}~${offset + batchData.length} / ${totalRecords}`);

        // ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬
        const batchResults = await this.processBatch(
          batchData,
          schema,
          job
        );

        // ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸
        const batchProcessed = batchResults.filter(r => r.success).length;
        const batchFailed = batchResults.filter(r => !r.success).length;

        processedRecords += batchProcessed;
        failedRecords += batchFailed;

        // ì§„í–‰ë¥  ê³„ì‚°
        const progressPercentage = Math.floor((processedRecords / totalRecords) * 100);

        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        await ragEmbeddingManager.updateJobStatus(job.id, "RUNNING", {
          processedRecords,
          failedRecords,
          progressPercentage,
        });

        // ì½œë°± í˜¸ì¶œ
        if (options?.onProgress) {
          options.onProgress({
            processed: processedRecords,
            total: totalRecords,
            percentage: progressPercentage,
          });
        }

        offset += batchSize;

        // ë°°ì¹˜ ê°„ ì§§ì€ ëŒ€ê¸° (Rate limiting ë°©ì§€)
        if (offset < totalRecords) {
          await this.delay(100);
        }
      }

      // ì‘ì—… ì™„ë£Œ
      await ragEmbeddingManager.updateJobStatus(job.id, "COMPLETED", {
        endTime: new Date(),
        processedRecords,
        failedRecords,
        progressPercentage: 100,
      });

      // ìŠ¤í‚¤ë§ˆ ìƒíƒœ ì—…ë°ì´íŠ¸
      await this.updateSchemaStatus(schema.id, job, processedRecords);

      console.log(`âœ… [Job ${job.id}] ì‘ì—… ì™„ë£Œ: ${processedRecords}ê±´ ì²˜ë¦¬, ${failedRecords}ê±´ ì‹¤íŒ¨`);
    } catch (error: any) {
      console.error(`âŒ [Job ${job.id}] ì‘ì—… ì‹¤íŒ¨:`, error);
      
      await ragEmbeddingManager.updateJobStatus(job.id, "FAILED", {
        endTime: new Date(),
        errorMessage: error.message || "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜",
        errorDetails: {
          stack: error.stack,
          name: error.name,
        },
      });

      throw error;
    }
  }

  /**
   * ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬
   */
  private async processBatch(
    batchData: Array<Record<string, unknown>>,
    schema: RagEmbeddingSchema,
    job: RagEmbeddingJob
  ): Promise<Array<{ success: boolean; error?: string }>> {
    const results: Array<{ success: boolean; error?: string }> = [];
    const documents: any[] = [];

    // ê° ë ˆì½”ë“œ ì²˜ë¦¬
    for (const record of batchData) {
      try {
        // í…ìŠ¤íŠ¸ ë³€í™˜
        const content = this.recordToText(record, schema);
        
        // ë²¡í„° ì„ë² ë”© ìƒì„±
        const embedding = await ragService.generateEmbedding(content);
        
        if (embedding.length === 0) {
          results.push({ success: false, error: "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨" });
          continue;
        }

        // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        const metadata = this.extractMetadata(record, schema);

        // ë¬¸ì„œ ID ìƒì„±
        const documentId = this.generateDocumentId(record, schema);

        // AI Search ë¬¸ì„œ êµ¬ì„±
        const document: any = {
          id: documentId,
          [schema.contentFieldName || "content"]: content,
          [schema.vectorFieldName || "content_vector"]: embedding,
        };

        // ë©”íƒ€ë°ì´í„° í•„ë“œ ì¶”ê°€
        if (metadata) {
          Object.assign(document, metadata);
        }

        documents.push(document);
        results.push({ success: true });
      } catch (error: any) {
        console.error(`ë ˆì½”ë“œ ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
        results.push({ success: false, error: error.message });
      }
    }

    // AI Searchì— ë°°ì¹˜ ì—…ë¡œë“œ
    if (documents.length > 0) {
      try {
        const searchService = getAzureSearchService(schema.searchIndexName);
        await searchService.initialize();
        await searchService.uploadDocuments(documents, {
          batchSize: 100,
          mergeOrUpload: true,
        });
      } catch (error: any) {
        console.error(`AI Search ì—…ë¡œë“œ ì‹¤íŒ¨:`, error);
        // ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë¬¸ì„œë¥¼ ì‹¤íŒ¨ë¡œ í‘œì‹œ
        return documents.map(() => ({ success: false, error: "AI Search ì—…ë¡œë“œ ì‹¤íŒ¨" }));
      }
    }

    return results;
  }

  /**
   * Databricks ì¿¼ë¦¬ êµ¬ì„±
   */
  private buildQuery(
    schema: RagEmbeddingSchema,
    job: RagEmbeddingJob,
    offset?: number,
    limit?: number
  ): string {
    let query = "";

    // ì»¤ìŠ¤í…€ ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if (schema.databricksQuery) {
      query = schema.databricksQuery;
    } else {
      // ê¸°ë³¸ ì¿¼ë¦¬ êµ¬ì„±
      const catalog = schema.databricksCatalog ? `${schema.databricksCatalog}.` : "";
      const schemaName = schema.databricksSchema ? `${schema.databricksSchema}.` : "";
      const table = schema.databricksTable;
      
      query = `SELECT * FROM ${catalog}${schemaName}${table}`;
      
      // ë‚ ì§œ í•„í„° (ê³¼ê±° ë°ì´í„° ì„ë² ë”© ì‹œ)
      if (job.jobType === "INCREMENTAL_HISTORICAL" && job.startDate && job.endDate) {
        // ë‚ ì§œ í•„ë“œê°€ ìˆë‹¤ê³  ê°€ì • (ì‹¤ì œë¡œëŠ” ìŠ¤í‚¤ë§ˆì—ì„œ ì§€ì • í•„ìš”)
        query += ` WHERE date >= '${job.startDate.toISOString().split('T')[0]}' AND date <= '${job.endDate.toISOString().split('T')[0]}'`;
      }
      
      // ìµœì‹  ë°ì´í„°ëŠ” ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
      if (job.jobType === "INCREMENTAL_NEW") {
        query += ` ORDER BY date DESC, timestamp DESC`;
      } else if (job.jobType === "INCREMENTAL_HISTORICAL") {
        query += ` ORDER BY date ASC, timestamp ASC`;
      }
    }

    // í˜ì´ì§•
    if (limit) {
      query += ` LIMIT ${limit}`;
    }
    if (offset) {
      query += ` OFFSET ${offset}`;
    }

    return query;
  }

  /**
   * ì¹´ìš´íŠ¸ ì¿¼ë¦¬ êµ¬ì„±
   */
  private buildCountQuery(
    schema: RagEmbeddingSchema,
    job: RagEmbeddingJob
  ): string {
    if (schema.databricksQuery) {
      // ì»¤ìŠ¤í…€ ì¿¼ë¦¬ì˜ ê²½ìš° ì„œë¸Œì¿¼ë¦¬ë¡œ ê°ì‹¸ê¸°
      return `SELECT COUNT(*) as count FROM (${schema.databricksQuery}) as subquery`;
    }

    const catalog = schema.databricksCatalog ? `${schema.databricksCatalog}.` : "";
    const schemaName = schema.databricksSchema ? `${schema.databricksSchema}.` : "";
    const table = schema.databricksTable;
    
    let query = `SELECT COUNT(*) as count FROM ${catalog}${schemaName}${table}`;
    
    if (job.jobType === "INCREMENTAL_HISTORICAL" && job.startDate && job.endDate) {
      query += ` WHERE date >= '${job.startDate.toISOString().split('T')[0]}' AND date <= '${job.endDate.toISOString().split('T')[0]}'`;
    }

    return query;
  }

  /**
   * ë ˆì½”ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
   */
  private recordToText(record: Record<string, unknown>, schema: RagEmbeddingSchema): string {
    // ì„ë² ë”© í•„ë“œê°€ ì§€ì •ë˜ì–´ ìˆìœ¼ë©´ í•´ë‹¹ í•„ë“œ ì‚¬ìš©
    if (schema.embeddingField && record[schema.embeddingField]) {
      return String(record[schema.embeddingField]);
    }

    // ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  í•„ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    const parts: string[] = [];
    
    for (const [key, value] of Object.entries(record)) {
      if (value !== null && value !== undefined) {
        if (typeof value === "object") {
          parts.push(`${key}: ${JSON.stringify(value)}`);
        } else {
          parts.push(`${key}: ${value}`);
        }
      }
    }

    return parts.join(" ");
  }

  /**
   * ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
   */
  private extractMetadata(
    record: Record<string, unknown>,
    schema: RagEmbeddingSchema
  ): Record<string, unknown> | null {
    if (!schema.metadataFields) {
      return null;
    }

    try {
      const metadataFields = JSON.parse(schema.metadataFields as string) as string[];
      const metadata: Record<string, unknown> = {};

      for (const field of metadataFields) {
        if (record[field] !== undefined) {
          metadata[field] = record[field];
        }
      }

      return Object.keys(metadata).length > 0 ? metadata : null;
    } catch (error) {
      console.warn("ë©”íƒ€ë°ì´í„° í•„ë“œ íŒŒì‹± ì‹¤íŒ¨:", error);
      return null;
    }
  }

  /**
   * ë¬¸ì„œ ID ìƒì„±
   */
  private generateDocumentId(
    record: Record<string, unknown>,
    schema: RagEmbeddingSchema
  ): string {
    // ID í•„ë“œê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if (record.id) {
      return `${schema.id}-${record.id}`;
    }
    
    // ê³ ìœ í•œ í‚¤ ì¡°í•©ìœ¼ë¡œ ID ìƒì„±
    const keyFields = ["symbol", "date", "timestamp", "code"];
    const keyParts: string[] = [schema.id];
    
    for (const field of keyFields) {
      if (record[field] !== undefined) {
        keyParts.push(String(record[field]));
      }
    }

    return keyParts.join("-");
  }

  /**
   * ìŠ¤í‚¤ë§ˆ ìƒíƒœ ì—…ë°ì´íŠ¸
   */
  private async updateSchemaStatus(
    schemaId: string,
    job: RagEmbeddingJob,
    processedRecords: number
  ): Promise<void> {
    const status = await ragEmbeddingManager.getSchemaStatus(schemaId);
    
    if (!status) {
      return;
    }

    const updates: any = {
      totalEmbeddedRecords: (status.totalEmbeddedRecords || 0) + processedRecords,
      currentJobId: null,
    };

    if (job.jobType === "INCREMENTAL_NEW") {
      updates.latestDataEmbeddedAt = new Date();
      updates.latestDataEmbeddedCount = processedRecords;
    } else if (job.jobType === "INCREMENTAL_HISTORICAL") {
      updates.historicalDataEmbeddedRecords = (status.historicalDataEmbeddedRecords || 0) + processedRecords;
      
      if (status.historicalDataTotalRecords) {
        const progress = Math.floor(
          ((status.historicalDataEmbeddedRecords || 0) + processedRecords) /
          status.historicalDataTotalRecords *
          100
        );
        updates.historicalDataProgressPercentage = progress;
        
        if (progress >= 100) {
          updates.historicalDataEmbeddingStatus = "COMPLETED";
        } else {
          updates.historicalDataEmbeddingStatus = "IN_PROGRESS";
        }
      }
    }

    await ragEmbeddingManager.updateSchemaStatus(schemaId, updates);
  }

  /**
   * ì§€ì—° í•¨ìˆ˜
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

export const ragEmbeddingWorker = new RAGEmbeddingWorker();

